{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Testing framework - Benchmark model\n",
    "\n",
    "Woodruff Wanderers - 1920 - 2,061 points  \n",
    "Big Weapon - 1920 - 2,212 points  \n",
    "Kebab DeBiryane - 1920 - 2,330 points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Setting up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T08:01:12.997770Z",
     "start_time": "2020-10-04T08:01:10.404689Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import median_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from footbot.data.utils import set_up_bigquery, run_query\n",
    "from footbot.optimiser.team_selector import select_team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T08:01:13.029396Z",
     "start_time": "2020-10-04T08:01:13.004908Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth', 60)\n",
    "pd.set_option('max_rows', 100)\n",
    "pd.set_option('max_columns', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T08:01:13.090734Z",
     "start_time": "2020-10-04T08:01:13.081157Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "client = set_up_bigquery('../secrets/service_account.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Training data SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T08:01:13.120111Z",
     "start_time": "2020-10-04T08:01:13.105505Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_sql = \\\n",
    "'''\n",
    "  -- training data\n",
    "WITH\n",
    "  teams AS (\n",
    "    -- lookup for team names\n",
    "  SELECT\n",
    "    DISTINCT team,\n",
    "    safe_team_name,\n",
    "    season\n",
    "  FROM\n",
    "    `footbot-001.fpl.elements_all` ),\n",
    "  --------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "  element_gameweeks AS (\n",
    "    -- historic player-fixture data as of event of interest\n",
    "  SELECT\n",
    "    eg.* EXCEPT(opponent_team),\n",
    "    ot.safe_team_name AS opponent_team,\n",
    "    e.element_all,\n",
    "    e.safe_web_name,\n",
    "    e.element_type,\n",
    "    e.safe_team_name AS team,\n",
    "  IF\n",
    "    (EXTRACT(DAYOFWEEK\n",
    "      FROM\n",
    "        kickoff_time) = 1,\n",
    "      1,\n",
    "      0) AS was_sunday,\n",
    "  IF\n",
    "    (EXTRACT(DAYOFWEEK\n",
    "      FROM\n",
    "        kickoff_time) NOT IN (1,\n",
    "        7),\n",
    "      1,\n",
    "      0) AS was_weekday,\n",
    "  IF\n",
    "    ((kickoff_time BETWEEN '2019-10-27'\n",
    "        AND '2020-03-29'\n",
    "        AND EXTRACT(HOUR\n",
    "        FROM\n",
    "          kickoff_time) > 15)\n",
    "      OR (kickoff_time NOT BETWEEN '2019-10-27'\n",
    "        AND '2020-03-29'\n",
    "        AND EXTRACT(HOUR\n",
    "        FROM\n",
    "          kickoff_time) > 14),\n",
    "      1,\n",
    "      0) AS was_late,\n",
    "  IF\n",
    "    ((kickoff_time BETWEEN '2019-10-27'\n",
    "        AND '2020-03-29'\n",
    "        AND EXTRACT(HOUR\n",
    "        FROM\n",
    "          kickoff_time) < 15)\n",
    "      OR (kickoff_time NOT BETWEEN '2019-10-27'\n",
    "        AND '2020-03-29'\n",
    "        AND EXTRACT(HOUR\n",
    "        FROM\n",
    "          kickoff_time) < 14),\n",
    "      1,\n",
    "      0) AS was_early,\n",
    "    DENSE_RANK() OVER(PARTITION BY e.element_all ORDER BY eg.season, eg.event, eg.kickoff_time) AS element_event_rank\n",
    "  FROM\n",
    "    `footbot-001.fpl.element_gameweeks_all` AS eg\n",
    "  INNER JOIN\n",
    "    `footbot-001.fpl.elements_all` AS e\n",
    "  ON\n",
    "    eg.element = e.element\n",
    "    AND eg.season = e.season\n",
    "  INNER JOIN\n",
    "    teams AS ot\n",
    "  ON\n",
    "    eg.opponent_team = ot.team\n",
    "    AND eg.season = ot.season\n",
    "  WHERE\n",
    "    (eg.season = '{season}'\n",
    "      AND eg.event < {event})\n",
    "    OR (eg.season < '{season}') -- before event of interest\n",
    "    ),\n",
    "  --------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "  elements AS (\n",
    "    -- element features as of event of interest\n",
    "  SELECT\n",
    "    DISTINCT element_all,\n",
    "    element_event_rank,\n",
    "    element_type,\n",
    "    team,\n",
    "    value,\n",
    "    AVG(total_points) OVER(PARTITION BY element_all ORDER BY element_event_rank RANGE BETWEEN 20 PRECEDING AND 1 PRECEDING) AS rolling_avg_total_points_element_p20,\n",
    "    AVG(assists) OVER(PARTITION BY element_all ORDER BY element_event_rank RANGE BETWEEN 20 PRECEDING AND 1 PRECEDING) AS rolling_avg_assists_element_p20,\n",
    "    AVG(clean_sheets) OVER(PARTITION BY element_all ORDER BY element_event_rank RANGE BETWEEN 20 PRECEDING AND 1 PRECEDING) AS rolling_avg_clean_sheets_element_p20,\n",
    "    AVG(goals_conceded) OVER(PARTITION BY element_all ORDER BY element_event_rank RANGE BETWEEN 20 PRECEDING AND 1 PRECEDING) AS rolling_avg_goals_conceded_element_p20,\n",
    "    AVG(saves) OVER(PARTITION BY element_all ORDER BY element_event_rank RANGE BETWEEN 20 PRECEDING AND 1 PRECEDING) AS rolling_avg_saves_element_p20,\n",
    "    AVG(minutes) OVER(PARTITION BY element_all ORDER BY element_event_rank RANGE BETWEEN 20 PRECEDING AND 1 PRECEDING) AS rolling_avg_minutes_element_p20,\n",
    "  FROM\n",
    "    element_gameweeks )\n",
    "  --------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "  --------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "  --------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "SELECT\n",
    "  eg.element_all,\n",
    "  safe_web_name,\n",
    "  season,\n",
    "  event,\n",
    "  total_points,\n",
    "  opponent_team,\n",
    "  was_home,\n",
    "  was_sunday,\n",
    "  was_weekday,\n",
    "  was_late,\n",
    "  was_early,\n",
    "  e.element_type,\n",
    "  e.team,\n",
    "  e.value,\n",
    "  rolling_avg_total_points_element_p20,\n",
    "  rolling_avg_assists_element_p20,\n",
    "  rolling_avg_clean_sheets_element_p20,\n",
    "  rolling_avg_goals_conceded_element_p20,\n",
    "  rolling_avg_saves_element_p20,\n",
    "  rolling_avg_minutes_element_p20\n",
    "FROM\n",
    "  element_gameweeks AS eg\n",
    "LEFT JOIN\n",
    "  elements AS e\n",
    "ON\n",
    "  eg.element_all = e.element_all\n",
    "  AND eg.element_event_rank = e.element_event_rank\n",
    "ORDER BY\n",
    "  element_all,\n",
    "  season,\n",
    "  event\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Prediction data SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T08:01:13.137319Z",
     "start_time": "2020-10-04T08:01:13.124071Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "predict_features_sql = \\\n",
    "'''\n",
    "-- prediction data\n",
    "WITH\n",
    "  teams AS (\n",
    "    -- lookup for team names\n",
    "  SELECT\n",
    "    DISTINCT team,\n",
    "    safe_team_name,\n",
    "    season\n",
    "  FROM\n",
    "    `footbot-001.fpl.elements_all` ),\n",
    "  --------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "  fixtures AS (\n",
    "    -- fixture data known ahead of time for fixtures from event of interest onwards\n",
    "  SELECT\n",
    "    f.* EXCEPT(opponent_team),\n",
    "    t.safe_team_name AS opponent_team\n",
    "  FROM (\n",
    "    SELECT\n",
    "      total_points,\n",
    "      minutes,\n",
    "      element,\n",
    "      event,\n",
    "      fixture,\n",
    "      opponent_team,\n",
    "      was_home,\n",
    "    IF\n",
    "      (EXTRACT(DAYOFWEEK\n",
    "        FROM\n",
    "          kickoff_time) = 1,\n",
    "        1,\n",
    "        0) AS was_sunday,\n",
    "    IF\n",
    "      (EXTRACT(DAYOFWEEK\n",
    "        FROM\n",
    "          kickoff_time) NOT IN (1,\n",
    "          7),\n",
    "        1,\n",
    "        0) AS was_weekday,\n",
    "    IF\n",
    "      ((kickoff_time BETWEEN '2019-10-27'\n",
    "          AND '2020-03-29'\n",
    "          AND EXTRACT(HOUR\n",
    "          FROM\n",
    "            kickoff_time) > 15)\n",
    "        OR (kickoff_time NOT BETWEEN '2019-10-27'\n",
    "          AND '2020-03-29'\n",
    "          AND EXTRACT(HOUR\n",
    "          FROM\n",
    "            kickoff_time) > 14),\n",
    "        1,\n",
    "        0) AS was_late,\n",
    "    IF\n",
    "      ((kickoff_time BETWEEN '2019-10-27'\n",
    "          AND '2020-03-29'\n",
    "          AND EXTRACT(HOUR\n",
    "          FROM\n",
    "            kickoff_time) < 15)\n",
    "        OR (kickoff_time NOT BETWEEN '2019-10-27'\n",
    "          AND '2020-03-29'\n",
    "          AND EXTRACT(HOUR\n",
    "          FROM\n",
    "            kickoff_time) < 14),\n",
    "        1,\n",
    "        0) AS was_early\n",
    "    FROM (\n",
    "      SELECT\n",
    "        total_points,\n",
    "        minutes,\n",
    "        element,\n",
    "        event,\n",
    "        fixture,\n",
    "        kickoff_time,\n",
    "        opponent_team,\n",
    "        was_home\n",
    "      FROM\n",
    "        `footbot-001.fpl.element_gameweeks_{season}`\n",
    "      WHERE\n",
    "        event >= {event} -- fixtures from event of interest onwards\n",
    "        ) ) AS f\n",
    "  INNER JOIN\n",
    "    teams AS t\n",
    "  ON\n",
    "    f.opponent_team = t.team\n",
    "    AND t.season = '{season}' ),\n",
    "  --------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "  element_gameweeks AS (\n",
    "    -- historic player-fixture data as of event of interest\n",
    "  SELECT\n",
    "    eg.* EXCEPT(opponent_team),\n",
    "    ot.safe_team_name AS opponent_team,\n",
    "    e.element_all,\n",
    "    e.safe_web_name,\n",
    "    e.element_type,\n",
    "    e.safe_team_name AS team,\n",
    "    DENSE_RANK() OVER(PARTITION BY e.element_all ORDER BY eg.season, eg.event, eg.kickoff_time) AS element_event_rank\n",
    "  FROM\n",
    "    `footbot-001.fpl.element_gameweeks_all` AS eg\n",
    "  INNER JOIN\n",
    "    `footbot-001.fpl.elements_all` AS e\n",
    "  ON\n",
    "    eg.element = e.element\n",
    "    AND eg.season = e.season\n",
    "  INNER JOIN\n",
    "    teams AS ot\n",
    "  ON\n",
    "    eg.opponent_team = ot.team\n",
    "    AND eg.season = ot.season\n",
    "  WHERE\n",
    "    (eg.season = '{season}'\n",
    "      AND eg.event <= {event})\n",
    "    OR (eg.season < '{season}') -- before event of interest\n",
    "    ),\n",
    "  --------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "  elements AS (\n",
    "    -- element features as of event of interest\n",
    "  SELECT\n",
    "    *\n",
    "  FROM (\n",
    "    SELECT\n",
    "      DISTINCT element_all,\n",
    "      element_type,\n",
    "      team,\n",
    "      value,\n",
    "      AVG(total_points) OVER(PARTITION BY element_all ORDER BY element_event_rank RANGE BETWEEN 20 PRECEDING AND 1 PRECEDING) AS rolling_avg_total_points_element_p20,\n",
    "      AVG(assists) OVER(PARTITION BY element_all ORDER BY element_event_rank RANGE BETWEEN 20 PRECEDING AND 1 PRECEDING) AS rolling_avg_assists_element_p20,\n",
    "      AVG(clean_sheets) OVER(PARTITION BY element_all ORDER BY element_event_rank RANGE BETWEEN 20 PRECEDING AND 1 PRECEDING) AS rolling_avg_clean_sheets_element_p20,\n",
    "      AVG(goals_conceded) OVER(PARTITION BY element_all ORDER BY element_event_rank RANGE BETWEEN 20 PRECEDING AND 1 PRECEDING) AS rolling_avg_goals_conceded_element_p20,\n",
    "      AVG(saves) OVER(PARTITION BY element_all ORDER BY element_event_rank RANGE BETWEEN 20 PRECEDING AND 1 PRECEDING) AS rolling_avg_saves_element_p20,\n",
    "      AVG(minutes) OVER(PARTITION BY element_all ORDER BY element_event_rank RANGE BETWEEN 20 PRECEDING AND 1 PRECEDING) AS rolling_avg_minutes_element_p20,\n",
    "      DENSE_RANK() OVER(PARTITION BY element_all ORDER BY element_event_rank DESC) AS is_current\n",
    "    FROM\n",
    "      element_gameweeks )\n",
    "  WHERE\n",
    "    is_current = 1 )\n",
    "  --------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "  --------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "  --------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "SELECT\n",
    "  a.element_all,\n",
    "  safe_web_name,\n",
    "  season,\n",
    "  f.event,\n",
    "  fixture,\n",
    "  total_points,\n",
    "  minutes,\n",
    "  opponent_team,\n",
    "  was_home,\n",
    "  was_sunday,\n",
    "  was_weekday,\n",
    "  was_late,\n",
    "  was_early,\n",
    "  e.element_type,\n",
    "  e.team,\n",
    "  e.value,\n",
    "  rolling_avg_total_points_element_p20,\n",
    "  rolling_avg_assists_element_p20,\n",
    "  rolling_avg_clean_sheets_element_p20,\n",
    "  rolling_avg_goals_conceded_element_p20,\n",
    "  rolling_avg_saves_element_p20,\n",
    "  rolling_avg_minutes_element_p20\n",
    "FROM\n",
    "  fixtures AS f\n",
    "INNER JOIN\n",
    "  `footbot-001.fpl.elements_all` AS a\n",
    "ON\n",
    "  f.element = a.element\n",
    "  AND a.season = '{season}'\n",
    "INNER JOIN\n",
    "  elements AS e\n",
    "ON\n",
    "  a.element_all = e.element_all\n",
    "ORDER BY\n",
    "  element_all,\n",
    "  season,\n",
    "  event\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Element data SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T08:01:13.151866Z",
     "start_time": "2020-10-04T08:01:13.141987Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "element_data_sql = \\\n",
    "'''\n",
    "SELECT\n",
    "  e.* EXCEPT( ts,\n",
    "    _is_recent)\n",
    "FROM (\n",
    "  SELECT\n",
    "    *,\n",
    "    ROW_NUMBER() OVER(PARTITION BY element_all ORDER BY ts DESC) _is_recent\n",
    "  FROM (\n",
    "    SELECT\n",
    "      element_all,\n",
    "      ed.element_type,\n",
    "      ed.team,\n",
    "      now_cost AS value,\n",
    "      datetime AS ts\n",
    "    FROM\n",
    "      `footbot-001.fpl.element_data_{season}` AS ed\n",
    "    INNER JOIN\n",
    "      `footbot-001.fpl.elements_all` AS e\n",
    "    ON\n",
    "      ed.element = e.element\n",
    "      AND e.season = '{season}'\n",
    "    WHERE\n",
    "      current_event + 1 <= {event}\n",
    "    UNION ALL\n",
    "    SELECT\n",
    "      element_all,\n",
    "      element_type,\n",
    "      team,\n",
    "      value,\n",
    "      eg.kickoff_time AS ts\n",
    "    FROM\n",
    "      `footbot-001.fpl.element_gameweeks_all` AS eg\n",
    "    INNER JOIN\n",
    "      `footbot-001.fpl.elements_all` AS e\n",
    "    ON\n",
    "      eg.element = e.element\n",
    "      AND eg.season = e.season\n",
    "    WHERE\n",
    "      (event <= {event}\n",
    "        AND eg.season = '{season}')\n",
    "      OR (eg.season < '{season}') ) ) AS e\n",
    "INNER JOIN (\n",
    "  SELECT\n",
    "    DISTINCT element_all\n",
    "  FROM\n",
    "    `footbot-001.fpl.elements_all`\n",
    "  WHERE\n",
    "    season = '{season}' ) AS s\n",
    "ON\n",
    "  e.element_all = s.element_all\n",
    "WHERE\n",
    "  _is_recent = 1\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T08:01:13.164689Z",
     "start_time": "2020-10-04T08:01:13.155569Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_data(sql, season, event):\n",
    "    formatted_sql = sql.format(season=season, event=event)\n",
    "    return run_query(formatted_sql, client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Modelling points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T08:01:13.184858Z",
     "start_time": "2020-10-04T08:01:13.169142Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_predict_df(\n",
    "    train_df,\n",
    "    predict_features_df\n",
    "):\n",
    "    meta_data = [\n",
    "        'element_all',\n",
    "        'safe_web_name',\n",
    "        'season',\n",
    "        'event',\n",
    "        'fixture',\n",
    "        'minutes',\n",
    "    ]\n",
    "    \n",
    "    train_df = train_df.drop(meta_data, axis=1, errors='ignore')\n",
    "    \n",
    "    categorical_features = [\n",
    "        'opponent_team',\n",
    "        'was_home',\n",
    "        'was_sunday',\n",
    "        'was_weekday',\n",
    "        'was_late',\n",
    "        'was_early',\n",
    "        'element_type',\n",
    "        'team',\n",
    "    ]\n",
    "\n",
    "    numerical_features = [\n",
    "        i for i in train_df.columns if i not in categorical_features + ['total_points']\n",
    "    ]\n",
    "\n",
    "    numerical_transformer = Pipeline(\n",
    "        [\n",
    "            ('impute missing values', SimpleImputer()),\n",
    "            ('scale numerical features', StandardScaler()),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    preprocess = ColumnTransformer(\n",
    "        [\n",
    "            (\n",
    "                'preprocess numerical features',\n",
    "                numerical_transformer,\n",
    "                numerical_features,\n",
    "            ),\n",
    "            (\n",
    "                'preprocess categorical features',\n",
    "                OneHotEncoder(handle_unknown='ignore'),\n",
    "                categorical_features,\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    model = Pipeline(\n",
    "        [\n",
    "            ('pre-process features', preprocess),\n",
    "            ('predictive model', Lasso(alpha=0.0020)),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    model.fit(train_df.drop('total_points', axis=1), train_df['total_points'])\n",
    "\n",
    "    predict_df = predict_features_df.copy()\n",
    "    predict_df['predicted_total_points'] = model.predict(\n",
    "        predict_df.drop(meta_data + ['total_points'], axis=1)\n",
    "    )\n",
    "    \n",
    "    return predict_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T08:01:13.198206Z",
     "start_time": "2020-10-04T08:01:13.188045Z"
    }
   },
   "outputs": [],
   "source": [
    "def aggregate_predictions(predict_df, start_event, end_event):\n",
    "    '''Average predicted points over event range.'''\n",
    "    num_events = end_event - start_event + 1\n",
    "    \n",
    "    predict_df = predict_df.copy()\n",
    "    predict_df = predict_df[\n",
    "        predict_df['event'].between(start_event, end_event)\n",
    "    ]\n",
    "    \n",
    "    predict_df = predict_df.groupby(\n",
    "        ['element_all', 'safe_web_name'], as_index=False\n",
    "    )[['predicted_total_points', 'total_points']].sum()\n",
    "    \n",
    "    predict_df['avg_predicted_total_points'] = predict_df['predicted_total_points'] / num_events\n",
    "    \n",
    "    predict_df = predict_df.drop(['predicted_total_points'], axis=1)\n",
    "    \n",
    "    return predict_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T08:01:13.209987Z",
     "start_time": "2020-10-04T08:01:13.203847Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_team_value(\n",
    "    element_data_df,\n",
    "    event,\n",
    "    first_team,\n",
    "    bench\n",
    "):\n",
    "    team_value = element_data_df[\n",
    "        element_data_df['element_all'].isin(first_team + bench)\n",
    "    ]['value'].sum()\n",
    "    \n",
    "    return team_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T08:01:13.233692Z",
     "start_time": "2020-10-04T08:01:13.213643Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_players_dict(\n",
    "    predict_df,\n",
    "    element_data_df,\n",
    "    start_event,\n",
    "    end_event\n",
    "):\n",
    "    agg_predict_df = aggregate_predictions(predict_df, start_event, end_event)\n",
    "\n",
    "    players_df = element_data_df.join(\n",
    "        agg_predict_df.set_index('element_all'),\n",
    "        on='element_all',\n",
    "    )\n",
    "    \n",
    "    players_df['avg_predicted_total_points'] = players_df['avg_predicted_total_points'].fillna(0)\n",
    "\n",
    "    players = players_df.rename(\n",
    "        columns={\"element_all\": \"element\"}\n",
    "    ).to_dict(orient='records')\n",
    "\n",
    "    return players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T08:01:13.269035Z",
     "start_time": "2020-10-04T08:01:13.251169Z"
    }
   },
   "outputs": [],
   "source": [
    "def update_purchase_prices(first_team, bench, purchase_price_dict):\n",
    "    for element in first_team + bench:\n",
    "        if element not in purchase_price_dict.keys():\n",
    "            element_value = element_data_df.loc[\n",
    "                element_data_df['element_all'] == element, 'value'\n",
    "            ].iloc[0]\n",
    "            purchase_price_dict[element] = element_value\n",
    "    \n",
    "    for element in list(purchase_price_dict):\n",
    "        if element not in first_team + bench:\n",
    "            del purchase_price_dict[element]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T08:01:13.286250Z",
     "start_time": "2020-10-04T08:01:13.275335Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_selling_price(market_price, purchase_price):\n",
    "    if market_price <= purchase_price:\n",
    "        return market_price\n",
    "    else:\n",
    "        selling_price_change = np.floor((market_price - purchase_price)/2)\n",
    "        return purchase_price + selling_price_change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T08:01:13.302373Z",
     "start_time": "2020-10-04T08:01:13.291701Z"
    }
   },
   "outputs": [],
   "source": [
    "def overwrite_values_with_selling_prices(purchase_price_dict, element_data_df):\n",
    "    for element, purchase_price in purchase_price_dict.items():\n",
    "        market_price = element_data_df.loc[\n",
    "            element_data_df['element_all'] == element,\n",
    "            'value'\n",
    "        ].iloc[0]\n",
    "        \n",
    "        selling_price = calculate_selling_price(market_price, purchase_price)\n",
    "        \n",
    "        element_data_df.loc[\n",
    "            element_data_df['element_all'] == element,\n",
    "            'value'\n",
    "        ] == selling_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T08:01:13.332061Z",
     "start_time": "2020-10-04T08:01:13.321223Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_prediction_metrics(predict_df, event):\n",
    "    \n",
    "    observations = predict_df[predict_df['event'] == event]['total_points']\n",
    "    predictions = predict_df[predict_df['event'] == event]['predicted_total_points']\n",
    "    \n",
    "    results = {\n",
    "        'event': event,\n",
    "        'median_absolute_error': median_absolute_error(observations, predictions),\n",
    "        'mean_squared_error': mean_squared_error(observations, predictions),\n",
    "        'r2_score': r2_score(observations, predictions),\n",
    "    }\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T08:01:13.355248Z",
     "start_time": "2020-10-04T08:01:13.339663Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_points(predict_df, first_team, captain, bench, transfers):\n",
    "\n",
    "    first_team_points = predict_df[\n",
    "        (predict_df['element_all'].isin(first_team))\n",
    "        & (predict_df['event'] == event)\n",
    "    ]['total_points'].sum()\n",
    "\n",
    "    captain_points = predict_df[\n",
    "        (predict_df['element_all'].isin(captain))\n",
    "        & (predict_df['event'] == event)\n",
    "    ]['total_points'].sum()\n",
    "    \n",
    "    transfers_points = min(0, -4 * (len(transfers['transfers_in']) - 1))\n",
    "    \n",
    "    return first_team_points + captain_points + transfers_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T08:01:13.372096Z",
     "start_time": "2020-10-04T08:01:13.360727Z"
    }
   },
   "outputs": [],
   "source": [
    "season = '1920'\n",
    "events = list(range(1, 30)) + list(range(39, 48))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T08:09:50.564982Z",
     "start_time": "2020-10-04T08:02:04.245621Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "event: 1\n",
      "getting training data\n",
      "getting prediction features data\n",
      "getting element data\n",
      "making predictions\n",
      "optimising transfers\n",
      "optimising team selection\n",
      "points: 70\n",
      "event: 2\n",
      "getting training data\n",
      "getting prediction features data\n",
      "getting element data\n",
      "making predictions\n",
      "optimising transfers\n",
      "optimising team selection\n",
      "points: 40\n",
      "event: 3\n",
      "getting training data\n",
      "getting prediction features data\n",
      "getting element data\n",
      "making predictions\n",
      "optimising transfers\n",
      "optimising team selection\n",
      "points: 67\n",
      "event: 4\n",
      "getting training data\n",
      "getting prediction features data\n",
      "getting element data\n",
      "making predictions\n",
      "optimising transfers\n",
      "optimising team selection\n",
      "points: 59\n",
      "event: 5\n",
      "getting training data\n",
      "getting prediction features data\n",
      "getting element data\n",
      "making predictions\n",
      "optimising transfers\n",
      "optimising team selection\n",
      "points: 54\n",
      "event: 6\n",
      "getting training data\n",
      "getting prediction features data\n",
      "getting element data\n",
      "making predictions\n",
      "optimising transfers\n",
      "optimising team selection\n",
      "points: 25\n",
      "event: 7\n",
      "getting training data\n",
      "getting prediction features data\n",
      "getting element data\n",
      "making predictions\n",
      "optimising transfers\n",
      "optimising team selection\n",
      "points: 50\n",
      "event: 8\n",
      "getting training data\n",
      "getting prediction features data\n",
      "getting element data\n",
      "making predictions\n",
      "optimising transfers\n",
      "optimising team selection\n",
      "points: 48\n",
      "event: 9\n",
      "getting training data\n",
      "getting prediction features data\n",
      "getting element data\n",
      "making predictions\n",
      "optimising transfers\n",
      "optimising team selection\n",
      "points: 43\n",
      "event: 10\n",
      "getting training data\n",
      "getting prediction features data\n",
      "getting element data\n",
      "making predictions\n",
      "optimising transfers\n",
      "optimising team selection\n",
      "points: 50\n",
      "event: 11\n",
      "getting training data\n",
      "getting prediction features data\n",
      "getting element data\n",
      "making predictions\n",
      "optimising transfers\n",
      "optimising team selection\n",
      "points: 84\n",
      "event: 12\n",
      "getting training data\n",
      "getting prediction features data\n",
      "getting element data\n",
      "making predictions\n",
      "optimising transfers\n",
      "optimising team selection\n",
      "points: 64\n",
      "event: 13\n",
      "getting training data\n",
      "getting prediction features data\n",
      "getting element data\n",
      "making predictions\n",
      "optimising transfers\n",
      "optimising team selection\n",
      "points: 71\n",
      "event: 14\n",
      "getting training data\n",
      "getting prediction features data\n",
      "getting element data\n",
      "making predictions\n",
      "optimising transfers\n",
      "optimising team selection\n",
      "points: 48\n",
      "event: 15\n",
      "getting training data\n",
      "getting prediction features data\n",
      "getting element data\n",
      "making predictions\n",
      "optimising transfers\n",
      "optimising team selection\n",
      "points: 52\n",
      "event: 16\n",
      "getting training data\n",
      "getting prediction features data\n",
      "getting element data\n",
      "making predictions\n",
      "optimising transfers\n",
      "optimising team selection\n",
      "points: 58\n",
      "event: 17\n",
      "getting training data\n",
      "getting prediction features data\n",
      "getting element data\n",
      "making predictions\n",
      "optimising transfers\n",
      "optimising team selection\n",
      "points: 60\n",
      "event: 18\n",
      "getting training data\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-529d47b97e05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'getting training data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mtrain_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_sql\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseason\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'getting prediction features data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mpredict_features_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict_features_sql\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseason\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-c56906ef1e44>\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(sql, season, event)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseason\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mformatted_sql\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseason\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseason\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrun_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformatted_sql\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/code/footbot/footbot/data/utils.py\u001b[0m in \u001b[0;36mrun_query\u001b[0;34m(sql, client)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mbqstorage_client\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbigquery_storage_v1beta1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBigQueryStorageClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbqstorage_client\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbqstorage_client\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/footbot/venv/lib/python3.7/site-packages/google/cloud/bigquery/job.py\u001b[0m in \u001b[0;36mto_dataframe\u001b[0;34m(self, bqstorage_client, dtypes, progress_bar_type, create_bqstorage_client)\u001b[0m\n\u001b[1;32m   3372\u001b[0m             \u001b[0mdtypes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3373\u001b[0m             \u001b[0mprogress_bar_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogress_bar_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3374\u001b[0;31m             \u001b[0mcreate_bqstorage_client\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_bqstorage_client\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3375\u001b[0m         )\n\u001b[1;32m   3376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/footbot/venv/lib/python3.7/site-packages/google/cloud/bigquery/table.py\u001b[0m in \u001b[0;36mto_dataframe\u001b[0;34m(self, bqstorage_client, dtypes, progress_bar_type, create_bqstorage_client)\u001b[0m\n\u001b[1;32m   1727\u001b[0m                 \u001b[0mprogress_bar_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogress_bar_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1728\u001b[0m                 \u001b[0mbqstorage_client\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbqstorage_client\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1729\u001b[0;31m                 \u001b[0mcreate_bqstorage_client\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_bqstorage_client\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1730\u001b[0m             )\n\u001b[1;32m   1731\u001b[0m             \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecord_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/footbot/venv/lib/python3.7/site-packages/google/cloud/bigquery/table.py\u001b[0m in \u001b[0;36mto_arrow\u001b[0;34m(self, progress_bar_type, bqstorage_client, create_bqstorage_client)\u001b[0m\n\u001b[1;32m   1541\u001b[0m             \u001b[0mrecord_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1542\u001b[0m             for record_batch in self._to_arrow_iterable(\n\u001b[0;32m-> 1543\u001b[0;31m                 \u001b[0mbqstorage_client\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbqstorage_client\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1544\u001b[0m             ):\n\u001b[1;32m   1545\u001b[0m                 \u001b[0mrecord_batches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/footbot/venv/lib/python3.7/site-packages/google/cloud/bigquery/table.py\u001b[0m in \u001b[0;36m_to_page_iterable\u001b[0;34m(self, bqstorage_download, tabledata_list_download, bqstorage_client)\u001b[0m\n\u001b[1;32m   1412\u001b[0m                 \u001b[0;31m# Iterate over the stream so that read errors are raised (and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1413\u001b[0m                 \u001b[0;31m# the method can then fallback to tabledata.list).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1414\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbqstorage_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1415\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1416\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/footbot/venv/lib/python3.7/site-packages/google/cloud/bigquery/_pandas_helpers.py\u001b[0m in \u001b[0;36m_download_table_bqstorage\u001b[0;34m(project_id, table, bqstorage_client, preserve_order, selected_fields, page_to_item)\u001b[0m\n\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m                     \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mworker_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_PROGRESS_INTERVAL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmpty\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pragma: NO COVER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/opt/python/Frameworks/Python.framework/Versions/3.7/lib/python3.7/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    177\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/opt/python/Frameworks/Python.framework/Versions/3.7/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "prediction_metrics_arr = []\n",
    "team_selection_arr = []\n",
    "players_df_arr = []\n",
    "purchase_price_dict = {}\n",
    "\n",
    "for event in events:\n",
    "    \n",
    "    print('event:', event)\n",
    "    \n",
    "    print('getting training data')\n",
    "    train_df = get_data(train_sql, season, event)\n",
    "    print('getting prediction features data')\n",
    "    predict_features_df = get_data(predict_features_sql, season, event)\n",
    "    print('getting element data')\n",
    "    element_data_df = get_data(element_data_sql, season, event)\n",
    "    overwrite_values_with_selling_prices(purchase_price_dict, element_data_df)\n",
    "    \n",
    "    print('making predictions')\n",
    "    predict_df = get_predict_df(\n",
    "        train_df,\n",
    "        predict_features_df\n",
    "    )\n",
    "    \n",
    "    prediction_metrics = calculate_prediction_metrics(predict_df, event)\n",
    "    prediction_metrics_arr.append(prediction_metrics)\n",
    "    \n",
    "    if event == 1:\n",
    "        existing_squad_elements = None\n",
    "        total_budget = 1000\n",
    "    else:\n",
    "        existing_squad_elements = first_team + bench\n",
    "        team_value = calculate_team_value(\n",
    "            element_data_df,\n",
    "            event,\n",
    "            first_team,\n",
    "            bench\n",
    "        )\n",
    "        total_budget = team_value + bank\n",
    "        \n",
    "    # optimise transfers over multiple event\n",
    "    players_transfers = get_players_dict(predict_df, element_data_df, event, event + 4)\n",
    "    try:\n",
    "        print('optimising transfers')\n",
    "        first_team, captain, bench, transfers = select_team(\n",
    "            players_transfers,\n",
    "            total_budget=total_budget,\n",
    "            optimise_key=\"avg_predicted_total_points\",\n",
    "            captain_factor=1,\n",
    "            bench_factor=0.1,\n",
    "            existing_squad_elements=existing_squad_elements,\n",
    "            transfer_penalty=0,\n",
    "            transfer_limit=1,\n",
    "        )\n",
    "        \n",
    "        team_value = calculate_team_value(\n",
    "            element_data_df,\n",
    "            event,\n",
    "            first_team,\n",
    "            bench\n",
    "        )\n",
    "        bank = total_budget - team_value\n",
    "    except:\n",
    "        print('transfers optimisation failed!')\n",
    "    \n",
    "    update_purchase_prices(first_team, bench, purchase_price_dict)\n",
    "    \n",
    "    # optimise team select over current event\n",
    "    players_selection = get_players_dict(predict_df, element_data_df, event, event)\n",
    "    try:\n",
    "        print('optimising team selection')\n",
    "        first_team, captain, bench, _ = select_team(\n",
    "            players_selection,\n",
    "            total_budget=total_budget,\n",
    "            optimise_key=\"avg_predicted_total_points\",\n",
    "            captain_factor=1,\n",
    "            bench_factor=0.1,\n",
    "            existing_squad_elements=first_team+bench,\n",
    "            transfer_penalty=0,\n",
    "            transfer_limit=0,\n",
    "        )\n",
    "        \n",
    "        if len(_['transfers_in']) != 0:\n",
    "            raise Exception\n",
    "            \n",
    "    except Exception:\n",
    "        print('selection optimisation failed!')\n",
    "    \n",
    "    points = calculate_points(predict_df, first_team, captain, bench, transfers)\n",
    "    print('points:', points)\n",
    "    \n",
    "    team_selection_arr.append({\n",
    "        'event': event,\n",
    "        'first_team': first_team,\n",
    "        'captain': captain,\n",
    "        'bench': bench,\n",
    "        'transfers': transfers,\n",
    "        'points': points,\n",
    "    })\n",
    "    \n",
    "    players_df_arr.append(\n",
    "        pd.DataFrame(players_transfers).join(\n",
    "            pd.DataFrame(players_selection).set_index('element')[['avg_predicted_total_points']],\n",
    "            on='element',\n",
    "            lsuffix='_transfers',\n",
    "            rsuffix='_selection'\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T08:01:36.765752Z",
     "start_time": "2020-10-04T08:01:10.412Z"
    }
   },
   "outputs": [],
   "source": [
    "np.sum([i['points'] for i in team_selection_arr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T08:01:36.769572Z",
     "start_time": "2020-10-04T08:01:10.415Z"
    }
   },
   "outputs": [],
   "source": [
    "2153/38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T08:01:36.776907Z",
     "start_time": "2020-10-04T08:01:10.418Z"
    }
   },
   "outputs": [],
   "source": [
    "# def calculate_team_total_points(df,\n",
    "# \t\t\t\t\t\t\t\tfirst_team_elements,\n",
    "# \t\t\t\t\t\t\t\tbench_elements,\n",
    "# \t\t\t\t\t\t\t\tevent,\n",
    "# \t\t\t\t\t\t\t\tnum_transfers=0,\n",
    "# \t\t\t\t\t\t\t\tcarried_over_transfers=0\n",
    "# \t\t\t\t\t\t\t\t):\n",
    "#     df = df.copy()\n",
    "#     df = df[df['event'] == event]\n",
    "#     df = df[df['element'].isin(list(first_team_elements) + list(bench_elements))]\n",
    "#     df['is_first_team'] = 0\n",
    "#     df.loc[df['element'].isin(list(first_team_elements)),'is_first_team'] = 1\n",
    "\n",
    "#     df['is_first_team'] = df['element'].apply(lambda x: 1 if x in first_team_elements else 0)\n",
    "\n",
    "#     df_group = df.groupby('element')[['predicted_total_points', 'total_points', 'minutes']].sum()\n",
    "\n",
    "#     df = df[['safe_web_name', 'element', 'value', 'element_type', 'is_first_team']].drop_duplicates()\n",
    "\n",
    "#     df = df.join(df_group, on='element')\n",
    "\n",
    "#     df.sort_values('predicted_total_points', ascending=False, inplace=True)\n",
    "\n",
    "#     captain_selection = df.iloc[0]['element']\n",
    "#     vice_selection = df.iloc[1]['element']\n",
    "\n",
    "#     is_captain_missing = len(df[(df['element'] == captain_selection) & (df['minutes'] == 0)])\n",
    "\n",
    "#     if is_captain_missing:\n",
    "#         df['is_captain'] = df['element'].apply(lambda x: 1 if x == vice_selection else 0)\n",
    "#     else:\n",
    "#         df['is_captain'] = df['element'].apply(lambda x: 1 if x == captain_selection else 0)\n",
    "\n",
    "#     missing_players = list(df[(df['minutes'] == 0) & (df['is_first_team'] == 1)]['element'])\n",
    "#     present_bench_players = list(df[(df['minutes'] > 0) & (df['is_first_team'] == 0)]['element'])\n",
    "#     num_missing_players = len(missing_players)\n",
    "#     num_present_bench_players = len(present_bench_players)\n",
    "\n",
    "#     if num_missing_players > 0:\n",
    "\n",
    "#         num_keepers = 1\n",
    "#         min_defenders = 3\n",
    "#         min_midfielders = 2\n",
    "#         min_strikers = 1\n",
    "\n",
    "#         df[df['minutes'] == 0]\n",
    "\n",
    "#         for i in range(0, min(3, num_missing_players, num_present_bench_players)):\n",
    "#             substitute = df[df['is_first_team'] == 0].iloc[i]['element']\n",
    "\n",
    "#             for missing_player in missing_players:\n",
    "#                 sub_loop_df = df.copy()\n",
    "\n",
    "#                 sub_loop_df.loc[sub_loop_df['element'] == substitute,'is_first_team'] = 1\n",
    "#                 sub_loop_df.loc[sub_loop_df['element'] == missing_player,'is_first_team'] = 0\n",
    "\n",
    "#                 num_team_keepers = len(\n",
    "#                     sub_loop_df[(sub_loop_df['is_first_team'] == 1) & (sub_loop_df['element_type'] == 1)])\n",
    "#                 num_team_defenders = len(\n",
    "#                     sub_loop_df[(sub_loop_df['is_first_team'] == 1) & (sub_loop_df['element_type'] == 2)])\n",
    "#                 num_team_midfielders = len(\n",
    "#                     sub_loop_df[(sub_loop_df['is_first_team'] == 1) & (sub_loop_df['element_type'] == 3)])\n",
    "#                 num_team_strikers = len(\n",
    "#                     sub_loop_df[(sub_loop_df['is_first_team'] == 1) & (sub_loop_df['element_type'] == 4)])\n",
    "\n",
    "#                 if (\n",
    "#                     (num_team_keepers == num_keepers)\n",
    "#                     & (num_team_defenders >= min_defenders)\n",
    "#                     & (num_team_midfielders >= min_midfielders)\n",
    "#                     & (num_team_strikers >= min_strikers)\n",
    "#                 ):\n",
    "#                     df = sub_loop_df.copy()\n",
    "#                     missing_players = list(df[(df['minutes'] == 0) & (df['is_first_team'] == 1)]['element'])\n",
    "#                     num_missing_players = len(missing_players)\n",
    "#                     break\n",
    "\n",
    "\n",
    "#     transfer_cost = max(num_transfers - carried_over_transfers - 1, 0) * 4\n",
    "\n",
    "#     team_total_points = \\\n",
    "#     sum(df[df['is_first_team'] == 1]['total_points'] * (df[df['is_first_team'] == 1]['is_captain'] + 1))\n",
    "\n",
    "#     team_predicted_total_points = \\\n",
    "#     sum(df[df['is_first_team'] == 1]['predicted_total_points'] * (df[df['is_first_team'] == 1]['is_captain'] + 1))\n",
    "\n",
    "#     return team_total_points - transfer_cost, team_predicted_total_points, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
